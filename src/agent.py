"""Agent Two: Multi-Agent Spec Generator by Netanel Systems.

Takes an agentic app idea and produces a complete, buildable specification
through 6 specialized agents:
  Lead → Researcher → Agent Designer → Workflow Designer → Infra Planner → Verifier

The Lead orchestrates (decides who runs next and passes context).
Assembly is done in Python — no expensive LLM call for stitching.

Usage:
    python -m src.agent "Build a code review agent that reviews PRs"

Output saved to: output/YYYY-MM-DD-idea-slug.md
"""

import os
import re
import sys
import time
from datetime import datetime

from langchain_core.messages import AIMessageChunk

from src.agents import lead_agent

# Subagent step metadata: (step_number, display_name, description, section_header)
AGENT_STEPS = {
    "researcher": (1, "Researcher", "Researching solutions and patterns", "Research Report"),
    "agent_designer": (2, "Agent Designer", "Designing agents, roles, and tools", "Agent Design"),
    "workflow_designer": (3, "Workflow Designer", "Planning communication and data flow", "Workflow Design"),
    "infra_planner": (4, "Infra Planner", "Planning memory, evals, and deployment", "Infrastructure Plan"),
    "verifier": (5, "Verifier", "Reviewing design for gaps and risks", "Verification Review"),
}
AGENT_ORDER = ["researcher", "agent_designer", "workflow_designer", "infra_planner", "verifier"]
TOTAL_STEPS = 5


def slugify(text: str, max_length: int = 50) -> str:
    """Convert text to a filename-safe slug."""
    slug = text.lower().strip()
    slug = re.sub(r"[^a-z0-9\s-]", "", slug)
    slug = re.sub(r"[\s]+", "-", slug)
    return slug[:max_length].rstrip("-")


def format_duration(seconds: float) -> str:
    """Format seconds into human-readable duration."""
    if seconds < 60:
        return f"{seconds:.0f}s"
    minutes = int(seconds // 60)
    secs = int(seconds % 60)
    return f"{minutes}m {secs}s"


def clean_report(text: str) -> str:
    """Remove internal agent noise from captured output.

    Strips Deep Agents middleware artifacts:
    - Todo list state updates
    - Raw tool JSON responses (Tavily, etc.)
    Works regardless of which model is used.
    """
    # 1. Remove "Updated todo list to [{...}, ...]" blocks.
    #    Uses bracket-depth tracking to handle nested structures safely.
    marker = "Updated todo list to ["
    result_parts = []
    i = 0
    while i < len(text):
        idx = text.find(marker, i)
        if idx == -1:
            result_parts.append(text[i:])
            break
        result_parts.append(text[i:idx])
        # Find matching closing bracket
        bracket_depth = 0
        j = idx + len(marker) - 1  # position of opening '['
        while j < len(text):
            if text[j] == "[":
                bracket_depth += 1
            elif text[j] == "]":
                bracket_depth -= 1
                if bracket_depth == 0:
                    i = j + 1
                    break
            j += 1
        else:
            # No matching bracket — skip rest
            i = len(text)
    text = "".join(result_parts)

    # 2. Remove raw Tavily JSON responses: {"query": "...", ..., "request_id": "..."}
    text = re.sub(
        r'\{"query":\s*".*?"request_id":\s*"[^"]*"\}',
        "",
        text,
        flags=re.DOTALL,
    )

    # 3. Remove any remaining raw JSON blocks that look like tool output
    #    (objects with "results" arrays from search tools)
    text = re.sub(
        r'\{".*?"results":\s*\[.*?\].*?"response_time".*?\}',
        "",
        text,
        flags=re.DOTALL,
    )

    # 4. Clean up whitespace artifacts from removals
    text = re.sub(r"\n{3,}", "\n\n", text)
    text = re.sub(r"  +", " ", text)

    return text.strip()


def assemble_spec(idea: str, subagent_reports: dict[str, str]) -> str:
    """Assemble the final specification from captured subagent outputs.

    Done in Python — no LLM needed for concatenation.
    Each report is cleaned of internal noise before assembly.
    """
    header = f"# Specification: {idea}\n\n"
    header += "*Generated by Agent Two — Netanel Systems*\n"
    header += f"*Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}*\n"
    header += f"*Agents: {len(subagent_reports)}/{TOTAL_STEPS} completed*\n"

    sections = []
    for i, agent_name in enumerate(AGENT_ORDER, 1):
        if agent_name in subagent_reports:
            _, _, _, section_title = AGENT_STEPS[agent_name]
            cleaned = clean_report(subagent_reports[agent_name])
            sections.append(f"---\n\n## {i}. {section_title}\n\n{cleaned}")

    return header + "\n\n" + "\n\n".join(sections)


def main() -> None:
    """Run agent-two with streaming progress and Python-side assembly."""
    if len(sys.argv) < 2:
        print("Usage: python -m src.agent 'your agentic app idea'")
        print()
        print("Example:")
        print("  python -m src.agent 'Build a code review agent that reviews PRs'")
        print("  python -m src.agent 'Build a customer support agent with memory'")
        sys.exit(1)

    idea = " ".join(sys.argv[1:])

    print(f"\n  Generating specification for: {idea}")
    print("=" * 60)
    print(f"  Pipeline: Lead + {TOTAL_STEPS} subagents")
    print(f"  Assembly: Python (no LLM stitching)")
    print("=" * 60)

    # --- State tracking ---
    current_agent = None
    agent_start_time = None
    overall_start = time.time()

    # Capture subagent outputs: accumulate streaming tokens per agent.
    # If a subagent runs twice (e.g. Verifier re-run), we keep the latest.
    subagent_reports: dict[str, str] = {}
    current_chunks: list[str] = []
    crashed = False

    try:
        for namespace, stream_mode, data in lead_agent.stream(
            {"messages": [{"role": "user", "content": idea}]},
            config={"configurable": {"thread_id": "1"}},
            stream_mode=["messages"],
            subgraphs=True,
        ):
            token, metadata = data
            agent_name = metadata.get("lc_agent_name", "")

            # --- Detect agent transition ---
            if agent_name and agent_name != current_agent:
                # Save previous subagent's accumulated output
                if current_agent in AGENT_STEPS and current_chunks:
                    subagent_reports[current_agent] = "".join(current_chunks)

                # Print completion time for previous agent
                if current_agent and agent_start_time:
                    elapsed = time.time() - agent_start_time
                    if current_agent in AGENT_STEPS:
                        print(f"  Done ({format_duration(elapsed)})")

                current_agent = agent_name
                agent_start_time = time.time()
                current_chunks = []

                # Print new agent status
                if agent_name in AGENT_STEPS:
                    step_num, display_name, description, _ = AGENT_STEPS[agent_name]
                    total_elapsed = time.time() - overall_start
                    print(
                        f"\n  [{step_num}/{TOTAL_STEPS}] {display_name}"
                        f"  ({format_duration(total_elapsed)} elapsed)"
                    )
                    print(f"  {description}...")
                elif agent_name == "lead":
                    total_elapsed = time.time() - overall_start
                    print(
                        f"\n  [Lead] Orchestrating..."
                        f"  ({format_duration(total_elapsed)} elapsed)"
                    )

            # --- Accumulate ONLY AI text from subagents ---
            # Skip ToolMessage tokens (raw JSON from tool results).
            # Only capture AIMessageChunk text content.
            if (
                agent_name in AGENT_STEPS
                and isinstance(token, AIMessageChunk)
                and token.text
            ):
                current_chunks.append(token.text)

    except Exception as e:
        # Save whatever the current subagent produced before crashing
        if current_agent in AGENT_STEPS and current_chunks:
            subagent_reports[current_agent] = "".join(current_chunks)
        crashed = True
        print(f"\n  Pipeline interrupted: {type(e).__name__}: {e}")
        print(f"  Recovering {len(subagent_reports)}/{TOTAL_STEPS} completed reports...")

    # Save last subagent if stream ended cleanly
    if not crashed and current_agent in AGENT_STEPS and current_chunks:
        subagent_reports[current_agent] = "".join(current_chunks)

    # Print completion for last agent
    if current_agent and agent_start_time:
        elapsed = time.time() - agent_start_time
        if current_agent in AGENT_STEPS:
            print(f"  Done ({format_duration(elapsed)})")

    total_time = time.time() - overall_start
    print(f"\n{'=' * 60}")
    print(f"  Completed in {format_duration(total_time)}")
    print(f"  Reports captured: {len(subagent_reports)}/{TOTAL_STEPS}")
    print("=" * 60)

    if not subagent_reports:
        print("\n  Error: No subagent reports captured.")
        sys.exit(1)

    # --- Assemble in Python, not LLM ---
    output = assemble_spec(idea, subagent_reports)

    # Save to file
    os.makedirs("output", exist_ok=True)
    date_str = datetime.now().strftime("%Y-%m-%d")
    slug = slugify(idea)
    filename = f"output/{date_str}-{slug}.md"

    with open(filename, "w") as f:
        f.write(output)

    print(f"\n  Saved to: {filename}")
    print(f"  Length: {len(output):,} characters")
    print(f"\n  View result:  cat {filename}")


if __name__ == "__main__":
    main()
